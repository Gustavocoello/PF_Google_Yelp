{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data_inicial/'  # Ruta donde est√†n los json\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iteramos sobre los nombres de archivos (del 1 al 13)\n",
    "for i in range(1, 14):\n",
    "    file_path = os.path.join(path, f'{i}.json')\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Generamos un √πnico DF\n",
    "NewYersey_Full_DF = pd.concat(dataframes, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las primeras 2000 filas\n",
    "subset_df = NewYersey_Full_DF.head(2000)\n",
    "\n",
    "# Guardar el DataFrame como un archivo JSON\n",
    "subset_df.to_json('subset_data.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1950000 entries, 0 to 1949999\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   user_id  float64\n",
      " 1   name     object \n",
      " 2   time     int64  \n",
      " 3   rating   int64  \n",
      " 4   text     object \n",
      " 5   pics     object \n",
      " 6   resp     object \n",
      " 7   gmap_id  object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 119.0+ MB\n",
      "None\n",
      "user_id    float64\n",
      "name        object\n",
      "time         int64\n",
      "rating       int64\n",
      "text        object\n",
      "pics        object\n",
      "resp        object\n",
      "gmap_id     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(NewYersey_Full_DF.head(10))  # Muestra las primeras filas del DataFrame combinado\n",
    "\n",
    "# Muestra un resumen del DataFrame incluyendo el tipo de datos de cada columna\n",
    "print(NewYersey_Full_DF.info(10))\n",
    "\n",
    "# Muestra los tipos de datos de todas las columnas\n",
    "print(NewYersey_Full_DF.dtypes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de nulos en user_id: 0\n",
      "Cantidad de nulos en name: 0\n",
      "Cantidad de nulos en time: 0\n",
      "Cantidad de nulos en rating: 0\n",
      "Cantidad de nulos en text: 0\n",
      "Cantidad de nulos en pics: 1894153\n",
      "Cantidad de nulos en resp: 1728764\n",
      "Cantidad de nulos en gmap_id: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar nulos en cada columna y imprimir por separado\n",
    "for column in NewYersey_Full_DF.columns:\n",
    "    nulos = NewYersey_Full_DF[column].isnull().sum()\n",
    "    print(f\"Cantidad de nulos en {column}: {nulos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar nulos en la columna 'text' donde 'rating' no es nulo\n",
    "NewYersey_Full_DF.loc[NewYersey_Full_DF['rating'].notnull(), 'text'] = NewYersey_Full_DF.loc[NewYersey_Full_DF['rating'].notnull(), 'text'].fillna(\"El cliente no dej√≥ comentarios para su valoraci√≥n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 1576097102614, 'text': \"Thank you! The team here at Bellibone is thrilled to hear such great feedback üíïWe hope you have a rockin' 2020 üí´\"}\n"
     ]
    }
   ],
   "source": [
    "print(NewYersey_Full_DF['resp'].dropna().iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Suponiendo que NewYersey_Full_DF es tu DataFrame\n",
    "# Crear un nuevo DataFrame a partir de la columna 'resp'\n",
    "resp_df = pd.json_normalize(NewYersey_Full_DF['resp'].dropna())\n",
    "\n",
    "# Concatenar el nuevo DataFrame con el original\n",
    "NewYersey_Full_DF_prueba = pd.concat([NewYersey_Full_DF.drop(columns=['resp']), resp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'name', 'time', 'rating', 'text', 'pics', 'gmap_id', 'time',\n",
       "       'text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewYersey_Full_DF_prueba.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores nulos en la columna 'resp': 1728764\n"
     ]
    }
   ],
   "source": [
    "# Contar los valores nulos en la columna 'resp'\n",
    "nulos_en_resp = NewYersey_Full_DF['resp'].isnull().sum()\n",
    "print(f\"Total de valores nulos en la columna 'resp': {nulos_en_resp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros: 1950000\n",
      "Total de filas con valores nulos (sin 'resp' y 'pics'): 864336\n",
      "Porcentaje de datos utilizables (sin 'resp' y 'pics'): 55.68%\n",
      "Total de filas duplicadas despu√©s de eliminar nulos: 27888\n",
      "Total de registros despu√©s de eliminar duplicados: 1057776\n",
      "Porcentaje final de datos utilizables despu√©s de eliminar nulos y duplicados: 54.24%\n"
     ]
    }
   ],
   "source": [
    "# Excluir las columnas 'resp' y 'pics'\n",
    "df_sin_resp_pics = NewYersey_Full_DF.drop(columns=['resp', 'pics'])\n",
    "\n",
    "# Realizar el an√°lisis sin considerar las columnas 'resp' y 'pics'\n",
    "total_registros = df_sin_resp_pics.shape[0]\n",
    "print(f\"Total de registros: {total_registros}\")\n",
    "\n",
    "# N√∫mero de filas con al menos un valor nulo, excluyendo 'resp' y 'pics'\n",
    "filas_con_nulos = df_sin_resp_pics.isnull().any(axis=1).sum()\n",
    "print(f\"Total de filas con valores nulos (sin 'resp' y 'pics'): {filas_con_nulos}\")\n",
    "\n",
    "# Porcentaje de datos utilizables (sin nulos, excluyendo 'resp' y 'pics')\n",
    "porcentaje_utilizable = ((total_registros - filas_con_nulos) / total_registros) * 100\n",
    "print(f\"Porcentaje de datos utilizables (sin 'resp' y 'pics'): {porcentaje_utilizable:.2f}%\")\n",
    "\n",
    "# Eliminar filas con valores nulos\n",
    "df_sin_nulos = df_sin_resp_pics.dropna()\n",
    "\n",
    "# Contar los duplicados en el DataFrame resultante\n",
    "duplicados = df_sin_nulos.duplicated().sum()\n",
    "print(f\"Total de filas duplicadas despu√©s de eliminar nulos: {duplicados}\")\n",
    "\n",
    "# Eliminar duplicados del DataFrame resultante\n",
    "df_final = df_sin_nulos.drop_duplicates()\n",
    "\n",
    "# Calcular el nuevo total de registros despu√©s de eliminar duplicados\n",
    "total_registros_final = df_final.shape[0]\n",
    "print(f\"Total de registros despu√©s de eliminar duplicados: {total_registros_final}\")\n",
    "\n",
    "# Calcular el porcentaje final de datos utilizables despu√©s de eliminar nulos y duplicados\n",
    "porcentaje_final = (total_registros_final / total_registros) * 100\n",
    "print(f\"Porcentaje final de datos utilizables despu√©s de eliminar nulos y duplicados: {porcentaje_final:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de calificaciones 1: 76742 (7.26%)\n",
      "Total de calificaciones 2: 34438 (3.26%)\n",
      "Total de calificaciones 3: 74687 (7.06%)\n",
      "Total de calificaciones 4: 181706 (17.18%)\n",
      "Total de calificaciones 5: 690203 (65.25%)\n"
     ]
    }
   ],
   "source": [
    "# Contar la cantidad de cada calificaci√≥n en la columna 'rating'\n",
    "conteo_ratings = df_final['rating'].value_counts().sort_index()\n",
    "\n",
    "# Calcular el total de registros en df_final\n",
    "total_registros_final = df_final.shape[0]\n",
    "\n",
    "# Mostrar los resultados y calcular el porcentaje\n",
    "for rating, count in conteo_ratings.items():\n",
    "    porcentaje = (count / total_registros_final) * 100\n",
    "    print(f\"Total de calificaciones {rating}: {count} ({porcentaje:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/acer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/acer/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras m√°s frecuentes:\n",
      "great: 296723\n",
      "good: 236131\n",
      "food: 193370\n",
      "place: 185428\n",
      "service: 164117\n",
      "staff: 112230\n",
      "nice: 109725\n",
      "friendly: 97296\n",
      "best: 88627\n",
      "always: 84796\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Descargar recursos necesarios de nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Unir todas las rese√±as en un solo texto\n",
    "text = ' '.join(df_final['text'].dropna())\n",
    "\n",
    "# Limpiar el texto (remover puntuaci√≥n, convertir a min√∫sculas, etc.)\n",
    "text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "\n",
    "# Tokenizar el texto (dividir en palabras)\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Remover stopwords (palabras comunes sin valor informativo)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Contar la frecuencia de las palabras\n",
    "word_freq = Counter(tokens)\n",
    "\n",
    "# Obtener las palabras m√°s comunes\n",
    "palabras_mas_frecuentes = word_freq.most_common(10)  # Puedes ajustar el n√∫mero de palabras m√°s comunes\n",
    "\n",
    "print(\"Palabras m√°s frecuentes:\")\n",
    "for word, freq in palabras_mas_frecuentes:\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2197/2913478406.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['sentimiento'] = df_final['text'].apply(analyze_sentiment)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positivo'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutro'\n",
    "    else:\n",
    "        return 'negativo'\n",
    "\n",
    "df_final['sentimiento'] = df_final['text'].apply(analyze_sentiment)\n",
    "\n",
    "# Contar la frecuencia de cada sentimiento\n",
    "sentiment_counts = df_final['sentimiento'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de rese√±as positivas: 84.19%\n",
      "Porcentaje de rese√±as negativas: 8.40%\n",
      "Porcentaje de rese√±as neutras: 7.42%\n"
     ]
    }
   ],
   "source": [
    "# Calcular el total de rese√±as\n",
    "total_sentimientos = sentiment_counts.sum()\n",
    "\n",
    "# Calcular el porcentaje de cada sentimiento\n",
    "porcentaje_positivo = (sentiment_counts['positivo'] / total_sentimientos) * 100\n",
    "porcentaje_negativo = (sentiment_counts['negativo'] / total_sentimientos) * 100\n",
    "porcentaje_neutro = (sentiment_counts['neutro'] / total_sentimientos) * 100\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Porcentaje de rese√±as positivas: {porcentaje_positivo:.2f}%\")\n",
    "print(f\"Porcentaje de rese√±as negativas: {porcentaje_negativo:.2f}%\")\n",
    "print(f\"Porcentaje de rese√±as neutras: {porcentaje_neutro:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de rese√±as positivas: 84.19%\n",
      "Porcentaje de rese√±as negativas: 8.40%\n",
      "Porcentaje de rese√±as neutras: 7.42%\n"
     ]
    }
   ],
   "source": [
    "# Calcular el total de rese√±as\n",
    "total_sentimientos = sentiment_counts.sum()\n",
    "\n",
    "# Calcular el porcentaje de cada sentimiento\n",
    "porcentaje_positivo = (sentiment_counts['positivo'] / total_sentimientos) * 100\n",
    "porcentaje_negativo = (sentiment_counts['negativo'] / total_sentimientos) * 100\n",
    "porcentaje_neutro = (sentiment_counts['neutro'] / total_sentimientos) * 100\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Porcentaje de rese√±as positivas: {porcentaje_positivo:.2f}%\")\n",
    "print(f\"Porcentaje de rese√±as negativas: {porcentaje_negativo:.2f}%\")\n",
    "print(f\"Porcentaje de rese√±as neutras: {porcentaje_neutro:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
